{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b373f9c",
   "metadata": {},
   "source": [
    "# NYC Traffic Collisions: Predicting Vulnerable Road User Type\n",
    "**Students:** רועי בנימיני, עוז ניסנבוים\n",
    "\n",
    "**Goal:** Classify collisions involving vulnerable road users (VRU) as either pedestrian or cyclist incidents.\n",
    "\n",
    "**Dataset:** [NYC Motor Vehicle Collisions](https://data.gov/) - 2.2M+ collision records\n",
    "\n",
    "---\n",
    "## 1. Setup and Data Loading\n",
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d947976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score, roc_curve)\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✅ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb728d",
   "metadata": {},
   "source": [
    "### 1.2 Load Data from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06632cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 400,000 rows × 29 columns\n",
      "Memory usage: 396.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Load data from GitHub repository\n",
    "url = \"https://github.com/Roybin12/machine-learning-2-project/raw/main/nyc_collisions_sample.zip\"\n",
    "df = pd.read_csv(url, compression='zip')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc677a2b",
   "metadata": {},
   "source": [
    "### 1.3 Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dad4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Column Types ===\n",
      "object     18\n",
      "int64       7\n",
      "float64     4\n",
      "dtype: int64\n",
      "\n",
      "=== Missing Values (Top 10) ===\n",
      "VEHICLE TYPE CODE 5              99.6\n",
      "CONTRIBUTING FACTOR VEHICLE 5    99.5\n",
      "VEHICLE TYPE CODE 4              98.4\n",
      "CONTRIBUTING FACTOR VEHICLE 4    98.3\n",
      "VEHICLE TYPE CODE 3              93.1\n",
      "CONTRIBUTING FACTOR VEHICLE 3    92.8\n",
      "OFF STREET NAME                  82.3\n",
      "CROSS STREET NAME                38.2\n",
      "ZIP CODE                         30.5\n",
      "BOROUGH                          30.5\n",
      "ON STREET NAME                   21.8\n",
      "VEHICLE TYPE CODE 2              20.1\n",
      "CONTRIBUTING FACTOR VEHICLE 2    16.1\n",
      "LOCATION                         10.8\n",
      "LONGITUDE                        10.8\n",
      "LATITUDE                         10.8\n",
      "VEHICLE TYPE CODE 1               0.7\n",
      "CONTRIBUTING FACTOR VEHICLE 1     0.4\n",
      "NUMBER OF PERSONS KILLED          0.0\n",
      "NUMBER OF PERSONS INJURED         0.0\n",
      "dtype: float64\n",
      "\n",
      "=== First 3 Rows ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH DATE</th>\n",
       "      <th>CRASH TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>OFF STREET NAME</th>\n",
       "      <th>NUMBER OF PERSONS INJURED</th>\n",
       "      <th>NUMBER OF PERSONS KILLED</th>\n",
       "      <th>NUMBER OF PEDESTRIANS INJURED</th>\n",
       "      <th>NUMBER OF PEDESTRIANS KILLED</th>\n",
       "      <th>NUMBER OF CYCLIST INJURED</th>\n",
       "      <th>NUMBER OF CYCLIST KILLED</th>\n",
       "      <th>NUMBER OF MOTORIST INJURED</th>\n",
       "      <th>NUMBER OF MOTORIST KILLED</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 1</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 2</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/21/2022</td>\n",
       "      <td>9:20</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11420.0</td>\n",
       "      <td>40.675106</td>\n",
       "      <td>-73.809790</td>\n",
       "      <td>(40.675106, -73.80979)</td>\n",
       "      <td>128 STREET</td>\n",
       "      <td>ROCKAWAY BOULEVARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Failure to Yield Right-of-Way</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4566168</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/26/2018</td>\n",
       "      <td>12:00</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11422.0</td>\n",
       "      <td>40.674520</td>\n",
       "      <td>-73.736084</td>\n",
       "      <td>(40.67452, -73.736084)</td>\n",
       "      <td>MERRICK BOULEVARD</td>\n",
       "      <td>234 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4052858</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>Box Truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/12/2020</td>\n",
       "      <td>12:17</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10304.0</td>\n",
       "      <td>40.608982</td>\n",
       "      <td>-74.088135</td>\n",
       "      <td>(40.608982, -74.088135)</td>\n",
       "      <td>DEKALB STREET</td>\n",
       "      <td>TARGEE STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4313485</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH DATE CRASH TIME        BOROUGH ZIP CODE   LATITUDE  LONGITUDE  \\\n",
       "0  09/21/2022       9:20         QUEENS  11420.0  40.675106 -73.809790   \n",
       "1  12/26/2018      12:00         QUEENS  11422.0  40.674520 -73.736084   \n",
       "2  05/12/2020      12:17  STATEN ISLAND  10304.0  40.608982 -74.088135   \n",
       "\n",
       "                  LOCATION                    ON STREET NAME  \\\n",
       "0   (40.675106, -73.80979)                        128 STREET   \n",
       "1   (40.67452, -73.736084)  MERRICK BOULEVARD                  \n",
       "2  (40.608982, -74.088135)  DEKALB STREET                      \n",
       "\n",
       "    CROSS STREET NAME OFF STREET NAME  NUMBER OF PERSONS INJURED  \\\n",
       "0  ROCKAWAY BOULEVARD             NaN                        2.0   \n",
       "1          234 STREET             NaN                        0.0   \n",
       "2       TARGEE STREET             NaN                        0.0   \n",
       "\n",
       "   NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n",
       "0                       0.0                              0   \n",
       "1                       0.0                              0   \n",
       "2                       0.0                              0   \n",
       "\n",
       "   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "\n",
       "   NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n",
       "0                         0                           2   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "\n",
       "   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n",
       "0                          0   Failure to Yield Right-of-Way   \n",
       "1                          0                     Unspecified   \n",
       "2                          0  Driver Inattention/Distraction   \n",
       "\n",
       "  CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3  \\\n",
       "0                   Unspecified                           NaN   \n",
       "1                   Unspecified                           NaN   \n",
       "2                   Unspecified                           NaN   \n",
       "\n",
       "  CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n",
       "0                           NaN                           NaN       4566168   \n",
       "1                           NaN                           NaN       4052858   \n",
       "2                           NaN                           NaN       4313485   \n",
       "\n",
       "                   VEHICLE TYPE CODE 1                  VEHICLE TYPE CODE 2  \\\n",
       "0                                Sedan  Station Wagon/Sport Utility Vehicle   \n",
       "1  Station Wagon/Sport Utility Vehicle                            Box Truck   \n",
       "2                                Sedan                                  NaN   \n",
       "\n",
       "  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \n",
       "0                 NaN                 NaN                 NaN  \n",
       "1                 NaN                 NaN                 NaN  \n",
       "2                 NaN                 NaN                 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset overview\n",
    "print(\"=== Column Types ===\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\n=== Missing Values (Top 10) ===\")\n",
    "missing = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "print(missing[missing > 0].round(1))\n",
    "print(f\"\\n=== First 3 Rows ===\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e52a40",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "### 2.1 Filter VRU Collisions & Create Target Variable\n",
    "We keep only collisions involving pedestrians or cyclists, then classify them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a26ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 400,000 rows\n",
      "VRU collisions: 34,463 rows (8.6%)\n",
      "\n",
      "=== Target Distribution ===\n",
      "Pedestrian    23109\n",
      "Cyclist       11354\n",
      "Name: TARGET, dtype: int64\n",
      "\n",
      "Class ratio: 2.0:1\n"
     ]
    }
   ],
   "source": [
    "# Filter: only collisions with pedestrians OR cyclists (not both, for clear classification)\n",
    "pedestrian_mask = (df['NUMBER OF PEDESTRIANS INJURED'] > 0) | (df['NUMBER OF PEDESTRIANS KILLED'] > 0)\n",
    "cyclist_mask = (df['NUMBER OF CYCLIST INJURED'] > 0) | (df['NUMBER OF CYCLIST KILLED'] > 0)\n",
    "\n",
    "# Keep VRU collisions, exclude mixed cases (both pedestrian and cyclist)\n",
    "vru_df = df[pedestrian_mask | cyclist_mask].copy()\n",
    "vru_df = vru_df[~(pedestrian_mask & cyclist_mask)]  # Remove mixed cases\n",
    "\n",
    "# Create target: 0 = Pedestrian, 1 = Cyclist\n",
    "vru_df['TARGET'] = np.where(\n",
    "    (vru_df['NUMBER OF PEDESTRIANS INJURED'] > 0) | (vru_df['NUMBER OF PEDESTRIANS KILLED'] > 0), \n",
    "    0, 1\n",
    ")\n",
    "\n",
    "print(f\"Original dataset: {len(df):,} rows\")\n",
    "print(f\"VRU collisions: {len(vru_df):,} rows ({len(vru_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\n=== Target Distribution ===\")\n",
    "print(vru_df['TARGET'].value_counts().rename({0: 'Pedestrian', 1: 'Cyclist'}))\n",
    "print(f\"\\nClass ratio: {vru_df['TARGET'].value_counts()[0] / vru_df['TARGET'].value_counts()[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5b07f",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering - Temporal Features\n",
    "Extract time-based features: hour, day of week, month, rush hour, and weekend indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6f424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Temporal Features Created ===\n",
      "        CRASH_DATETIME  HOUR  DAY_OF_WEEK  MONTH  IS_WEEKEND  IS_RUSH_HOUR  \\\n",
      "13 2016-07-20 11:42:00    11            2      7           0             0   \n",
      "22 2014-03-17 21:30:00    21            0      3           0             0   \n",
      "52 2013-12-29 16:50:00    16            6     12           1             1   \n",
      "83 2019-12-23 07:04:00     7            0     12           0             1   \n",
      "93 2017-09-18 10:45:00    10            0      9           0             0   \n",
      "\n",
      "   TIME_OF_DAY  \n",
      "13     Morning  \n",
      "22     Evening  \n",
      "52   Afternoon  \n",
      "83     Morning  \n",
      "93     Morning  \n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "vru_df['CRASH_DATETIME'] = pd.to_datetime(vru_df['CRASH DATE'] + ' ' + vru_df['CRASH TIME'])\n",
    "\n",
    "# Temporal features\n",
    "vru_df['HOUR'] = vru_df['CRASH_DATETIME'].dt.hour\n",
    "vru_df['DAY_OF_WEEK'] = vru_df['CRASH_DATETIME'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "vru_df['MONTH'] = vru_df['CRASH_DATETIME'].dt.month\n",
    "vru_df['YEAR'] = vru_df['CRASH_DATETIME'].dt.year\n",
    "\n",
    "# Derived features\n",
    "vru_df['IS_WEEKEND'] = (vru_df['DAY_OF_WEEK'] >= 5).astype(int)\n",
    "vru_df['IS_RUSH_HOUR'] = vru_df['HOUR'].isin([7, 8, 9, 16, 17, 18]).astype(int)\n",
    "vru_df['TIME_OF_DAY'] = pd.cut(vru_df['HOUR'], bins=[-1, 6, 12, 18, 24], \n",
    "                                labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
    "\n",
    "print(\"=== Temporal Features Created ===\")\n",
    "print(vru_df[['CRASH_DATETIME', 'HOUR', 'DAY_OF_WEEK', 'MONTH', 'IS_WEEKEND', 'IS_RUSH_HOUR', 'TIME_OF_DAY']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094e180",
   "metadata": {},
   "source": [
    "### 2.3 Load Data with Geocoded Coordinates\n",
    "Merge raw data with previously geocoded locations from Google Maps API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04ac577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Ready ===\n",
      "Raw data: 400,000 rows\n",
      "Geocoded locations merged: 27,086\n",
      "VRU records: 34,463\n",
      "\n",
      "Target distribution:\n",
      "Pedestrian    23109\n",
      "Cyclist       11354\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# Load raw data + merge geocoded coordinates\n",
    "# ===========================================\n",
    "\n",
    "# 1. Load raw data\n",
    "url_raw = \"https://github.com/Roybin12/machine-learning-2-project/raw/main/nyc_collisions_sample.zip\"\n",
    "df = pd.read_csv(url_raw, compression='zip')\n",
    "\n",
    "# 2. Load geocoded coordinates from previous API run\n",
    "url_geo = \"https://raw.githubusercontent.com/Roybin12/machine-learning-2-project/main/geocoded_locations.csv\"\n",
    "geo_df = pd.read_csv(url_geo)\n",
    "\n",
    "# 3. Merge geocoded coordinates into raw data\n",
    "for _, row in geo_df.iterrows():\n",
    "    idx = int(row['index'])\n",
    "    if idx in df.index:\n",
    "        df.loc[idx, 'LATITUDE'] = row['lat']\n",
    "        df.loc[idx, 'LONGITUDE'] = row['lng']\n",
    "\n",
    "# 4. Filter VRU only\n",
    "pedestrian_mask = (df['NUMBER OF PEDESTRIANS INJURED'] > 0) | (df['NUMBER OF PEDESTRIANS KILLED'] > 0)\n",
    "cyclist_mask = (df['NUMBER OF CYCLIST INJURED'] > 0) | (df['NUMBER OF CYCLIST KILLED'] > 0)\n",
    "vru_df = df[pedestrian_mask | cyclist_mask].copy()\n",
    "vru_df = vru_df[~(pedestrian_mask & cyclist_mask)]\n",
    "\n",
    "# 5. Create target variable\n",
    "vru_df['TARGET'] = np.where(\n",
    "    (vru_df['NUMBER OF PEDESTRIANS INJURED'] > 0) | (vru_df['NUMBER OF PEDESTRIANS KILLED'] > 0), \n",
    "    0, 1\n",
    ")\n",
    "\n",
    "# 6. Create temporal features\n",
    "vru_df['CRASH_DATETIME'] = pd.to_datetime(vru_df['CRASH DATE'] + ' ' + vru_df['CRASH TIME'])\n",
    "vru_df['HOUR'] = vru_df['CRASH_DATETIME'].dt.hour\n",
    "vru_df['DAY_OF_WEEK'] = vru_df['CRASH_DATETIME'].dt.dayofweek\n",
    "vru_df['MONTH'] = vru_df['CRASH_DATETIME'].dt.month\n",
    "vru_df['IS_WEEKEND'] = (vru_df['DAY_OF_WEEK'] >= 5).astype(int)\n",
    "vru_df['IS_RUSH_HOUR'] = vru_df['HOUR'].isin([7, 8, 9, 16, 17, 18]).astype(int)\n",
    "\n",
    "# 7. Select features for modeling\n",
    "feature_cols = ['BOROUGH', 'LATITUDE', 'LONGITUDE', 'HOUR', 'DAY_OF_WEEK', 'MONTH', \n",
    "                'IS_WEEKEND', 'IS_RUSH_HOUR', 'CONTRIBUTING FACTOR VEHICLE 1', 'VEHICLE TYPE CODE 1']\n",
    "model_df = vru_df[feature_cols + ['TARGET']].copy()\n",
    "\n",
    "print(f\"=== Data Ready ===\")\n",
    "print(f\"Raw data: {len(df):,} rows\")\n",
    "print(f\"Geocoded locations merged: {len(geo_df):,}\")\n",
    "print(f\"VRU records: {len(model_df):,}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(model_df['TARGET'].value_counts().rename({0: 'Pedestrian', 1: 'Cyclist'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c3d18",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "### 3.1 Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89be45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Missing Values ===\n",
      "BOROUGH                             | 6,834 (19.8%)\n",
      "LATITUDE                            | 490 (1.4%)\n",
      "LONGITUDE                           | 490 (1.4%)\n",
      "CONTRIBUTING FACTOR VEHICLE 1       | 872 (2.5%)\n",
      "VEHICLE TYPE CODE 1                 | 1,804 (5.2%)\n",
      "\n",
      "Total rows: 34,463\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in model_df\n",
    "print(\"=== Missing Values ===\")\n",
    "for col in model_df.columns:\n",
    "    missing = model_df[col].isnull().sum()\n",
    "    pct = missing / len(model_df) * 100\n",
    "    if missing > 0:\n",
    "        print(f\"{col:35} | {missing:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal rows: {len(model_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d87a7",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values\n",
    "- Coordinates: Drop rows (only 1.4%)\n",
    "- Categorical: Fill with 'Unknown'\n",
    "- Vehicle Type: Reduce to top 10 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecf5b7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing coords: 33,973 rows (98.6%)\n",
      "\n",
      "=== After Cleaning ===\n",
      "Missing values: 0\n",
      "\n",
      "Vehicle Type categories: 11\n",
      "Sedan                                  8498\n",
      "Station Wagon/Sport Utility Vehicle    7386\n",
      "PASSENGER VEHICLE                      4653\n",
      "Other                                  3681\n",
      "Bike                                   2488\n",
      "SPORT UTILITY / STATION WAGON          2176\n",
      "Unknown                                1791\n",
      "Taxi                                   1138\n",
      "UNKNOWN                                 973\n",
      "TAXI                                    643\n",
      "Pick-up Truck                           546\n",
      "Name: VEHICLE TYPE CODE 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop rows with missing coordinates\n",
    "df_clean = model_df.dropna(subset=['LATITUDE', 'LONGITUDE']).copy()\n",
    "print(f\"After dropping missing coords: {len(df_clean):,} rows ({len(df_clean)/len(model_df)*100:.1f}%)\")\n",
    "\n",
    "# 2. Fill categorical missing values\n",
    "df_clean['BOROUGH'] = df_clean['BOROUGH'].fillna('Unknown')\n",
    "df_clean['CONTRIBUTING FACTOR VEHICLE 1'] = df_clean['CONTRIBUTING FACTOR VEHICLE 1'].fillna('Unknown')\n",
    "df_clean['VEHICLE TYPE CODE 1'] = df_clean['VEHICLE TYPE CODE 1'].fillna('Unknown')\n",
    "\n",
    "# 3. Reduce Vehicle Type categories (keep top 10, rest as 'Other')\n",
    "top_vehicles = df_clean['VEHICLE TYPE CODE 1'].value_counts().nlargest(10).index.tolist()\n",
    "df_clean['VEHICLE TYPE CODE 1'] = df_clean['VEHICLE TYPE CODE 1'].apply(\n",
    "    lambda x: x if x in top_vehicles else 'Other'\n",
    ")\n",
    "\n",
    "print(f\"\\n=== After Cleaning ===\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"\\nVehicle Type categories: {df_clean['VEHICLE TYPE CODE 1'].nunique()}\")\n",
    "print(df_clean['VEHICLE TYPE CODE 1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6508a265",
   "metadata": {},
   "source": [
    "### 3.3 Standardize Category Names\n",
    "Fix duplicate categories with different cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d58861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vehicle Types (Cleaned) ===\n",
      "Sedan                                  13151\n",
      "Station Wagon/Sport Utility Vehicle     9562\n",
      "Other                                   3681\n",
      "Unknown                                 2764\n",
      "Bike                                    2488\n",
      "Taxi                                    1781\n",
      "Pick-up Truck                            546\n",
      "Name: VEHICLE TYPE CODE 1, dtype: int64\n",
      "\n",
      "Categories: 7\n"
     ]
    }
   ],
   "source": [
    "# Standardize Vehicle Type names\n",
    "vehicle_mapping = {\n",
    "    'PASSENGER VEHICLE': 'Sedan',\n",
    "    'SPORT UTILITY / STATION WAGON': 'Station Wagon/Sport Utility Vehicle',\n",
    "    'UNKNOWN': 'Unknown',\n",
    "    'TAXI': 'Taxi'\n",
    "}\n",
    "df_clean['VEHICLE TYPE CODE 1'] = df_clean['VEHICLE TYPE CODE 1'].replace(vehicle_mapping)\n",
    "\n",
    "print(\"=== Vehicle Types (Cleaned) ===\")\n",
    "print(df_clean['VEHICLE TYPE CODE 1'].value_counts())\n",
    "print(f\"\\nCategories: {df_clean['VEHICLE TYPE CODE 1'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c4686",
   "metadata": {},
   "source": [
    "### 3.4 Final Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2b931e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Dataset ===\n",
      "Rows: 33,973\n",
      "Columns: 11\n",
      "Missing values: 0\n",
      "\n",
      "=== Column Summary ===\n",
      "BOROUGH                             | object   | 6 unique\n",
      "LATITUDE                            | float64  | 21,600 unique\n",
      "LONGITUDE                           | float64  | 20,270 unique\n",
      "HOUR                                | int64    | 24 unique\n",
      "DAY_OF_WEEK                         | int64    | 7 unique\n",
      "MONTH                               | int64    | 12 unique\n",
      "IS_WEEKEND                          | int32    | 2 unique\n",
      "IS_RUSH_HOUR                        | int32    | 2 unique\n",
      "CONTRIBUTING FACTOR VEHICLE 1       | object   | 56 unique\n",
      "VEHICLE TYPE CODE 1                 | object   | 7 unique\n",
      "TARGET                              | int32    | 2 unique\n",
      "\n",
      "=== Target Distribution ===\n",
      "Pedestrian    22833\n",
      "Cyclist       11140\n",
      "Name: TARGET, dtype: int64\n",
      "Ratio: 2.05:1\n"
     ]
    }
   ],
   "source": [
    "# Final data summary\n",
    "print(\"=== Final Dataset ===\")\n",
    "print(f\"Rows: {len(df_clean):,}\")\n",
    "print(f\"Columns: {len(df_clean.columns)}\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n=== Column Summary ===\")\n",
    "for col in df_clean.columns:\n",
    "    dtype = df_clean[col].dtype\n",
    "    unique = df_clean[col].nunique()\n",
    "    print(f\"{col:35} | {str(dtype):8} | {unique:,} unique\")\n",
    "\n",
    "print(f\"\\n=== Target Distribution ===\")\n",
    "print(df_clean['TARGET'].value_counts().rename({0: 'Pedestrian', 1: 'Cyclist'}))\n",
    "print(f\"Ratio: {df_clean['TARGET'].value_counts()[0] / df_clean['TARGET'].value_counts()[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfaa410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
